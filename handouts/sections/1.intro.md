# Introduction

This tutorial is designed for people with very little or no knowledge
of dataflow programming and/or hardware architectures. You should have
already seen a short demo explaining the Maxeler tool-chain and had a
go at one of their simple training exercises to familiarise yourself
with the development flow.

In this tutorial, we will be working our way towards a hardware
architecture for multiplying small matrices (up to 16 x 16
elements). We will:

1. build a simple architecture for vector-vector
   multiplication
2. extend this to a matrix-vector multiplier
3. and finally, a matrix-matrix multiplier

__Note__ Each exercise builds on the previous one(s). Make sure you get
the first ones right! There is plenty of time and don't be shy to ask
for help.

In your MaxIDE you should see a skeleton project.

TODO: describe files

# Vector-Vector Multiplier

We will start by building a simple vector-vector multiplier. If
$\vec{a}$ and $\vec{b}$ are our vectors, then you should implement:

```
dot = 0
for i = 0, i < n, i++
   dot += a[i] * b[i]
output dot
```

The first step would be to build the design shown in Figure 1.a.
This design takes one input per clock cycle. Note that you will have
to _reduce the results on the CPU side_.

\begin{figure}[ht!]
  \center
  \includegraphics[width=\columnwidth]{figures/papaa14vector-vector.pdf}
  \caption{Designs for vector-vector multiplication: a) single output
  per clock cycle, b) fully unrolled design}
  \label{fig:vector-vector}
\end{figure}


__Exercise 1.1__ Build a vector-vector multiplier which produces one
value per clock cycle as shown in Figure 1.a.


Now let's exploit the on-chip resources to increase the level of
parallelism.
In your implementation you can use a DFEVector<DFEVar>, which (as the
name suggests) is a _vector_ of data streams.

We can define a vector type as shown below:

```
DFEVectorType<DFEVar> vectorType = new DFEVectorType>(scalarType, N)
```

where _scalarType_ is the type of one input stream and _N_ is the
number of streams.

We can read a vector of data as shown below:

```
DFEVector<DFE> in = io.input("inputName", vectorType)
```

__Exercise 1.2__ Using a DFEVector, implement the design shown in Figure 1.b.

### Discussion

As you may have noticed, this design is _memory bound_.
If we are using PCIe there is little point in increasing the
parallelism beyond (N = 2). If we are using DRAM we should limit the
parallelism to N = 48.


# Matrix-Vector Multiplier

Let's extend the vector-vector multiplier we built to a matrix-vector
multiplier.

One approach is to:

1. Store the vector on-chip

2. Stream the matrix row by row

We can use a controlled input to select on which _kernel cycle_ we
want to read from the stream. The syntax for controlled inputs is:

```
DFEVar in = io.input("inputName", type, enable)
```

We can use a controlled input to create an on-chip cache, by only
enabling the input for the first cycle. To do this we will also need
to create a counter, for which the syntax is:

```
DFEVar count = control.count.simpleCounter(counterBitWidth, maximumValue)
```

\begin{figure}[ht!]
  \center
  \includegraphics[width=\columnwidth]{figures/papaa14vector-matrix.pdf}
  \caption{Partially unrolled design for matrix vector multiplication.}
  \label{fig:matrix-vector}
\end{figure}


__Exercise 2.1__ Using counters and controlled inputs, implement the
matrix-vector multiplier described above (and also in Figure
\ref{fig:matrix-vector}).

\begin{figure}[ht!]
  \center
  \includegraphics[width=\columnwidth]{figures/papaa14vector-matrix-full.pdf}
  \caption{Partially unrolled design for matrix vector multiplication.}
  \label{fig:matrix-vector-full}
\end{figure}


__Exercise 2.2__ Implement a fully unrolled matrix-vector multiplier,
as shown in Figure \ref{fig:matrix-vector-full}.  _Hint_ This should
take all matrix and vector values as input and produce the result in a
single _kernel cycle_.

# Matrix-Matrix Multiplier

You should, by now, be familiar with all the concepts required to
extend the matrix-vector multiplier from exercise 2.2 to a fully
unrolled matrix-matrix multiplier.

__Exercise 2.3__ Implement a fully unrolled matrix-matrix multiplier.

# Wrap-Up

You can find the exercises and solutions online at
\url{https://github.com/custom-computing-ic/papaa14}.

If you want to read more about scalable implementations for matrix
multiplication on FPGAs, consult \cite{zhuo2004scalable} and
\cite{zhuo2008high}.
